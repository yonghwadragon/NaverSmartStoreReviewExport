# smartstore_review_scraper.py

import time
import pandas as pd
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright


# ================================
# ë¦¬ë·° ì¹´ë“œ 1ê°œ íŒŒì‹±
# ================================
def parse_review_card(card):

    # ---------------------------
    # ë‹‰ë„¤ì„
    # ---------------------------
    nickname_el = card.select_one(".Db9Dtnf7gY strong")
    nickname = nickname_el.get_text(strip=True) if nickname_el else ""

    # ---------------------------
    # ë‚ ì§œ
    # ---------------------------
    date_el = card.select_one(".Db9Dtnf7gY span:nth-of-type(1)")
    date = date_el.get_text(strip=True) if date_el else ""

    # ---------------------------
    # í‰ì  (5, 4, 3â€¦)
    # ---------------------------
    rating_el = card.select_one("em.n6zq2yy0KA")
    rating = rating_el.get_text(strip=True) if rating_el else ""

    # ---------------------------
    # ì˜µì…˜ (ì²« í…ìŠ¤íŠ¸ë§Œ)
    # ---------------------------
    option = ""
    option_box = card.select_one(".b_caIle8kC")
    if option_box:
        # ëª¨ë“  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì™€ì„œ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©
        all_texts = list(option_box.stripped_strings)
        option = all_texts[0] if all_texts else ""



    # ---------------------------
    # êµ¬ë§¤ì ì •ë³´
    # ---------------------------
    buyer_el = card.select_one(".eWRrdDdSzW")
    buyer_info = buyer_el.get_text(" ", strip=True) if buyer_el else ""

    # ---------------------------
    # ìë™ ë¼ë²¨ (ìœ í†µê¸°í•œ/í¬ì¥/í¸ë¦¬ ë“±)
    # ---------------------------
    label_el = card.select_one(".h8uqAeqIe7")
    label_info = label_el.get_text(" ", strip=True) if label_el else ""

    # auto_label = buyer_info + label_info í•©ì³ì„œ ì €ì¥
    auto_label = " | ".join(x for x in [buyer_info, label_info] if x)

    # ---------------------------
    # ë³¸ë¬¸
    # ---------------------------
    content_el = card.select_one(".KqJ8Qqw082 span")
    content = content_el.get_text(" ", strip=True) if content_el else ""

    # ---------------------------
    # ì´ë¯¸ì§€ ê°œìˆ˜ (ì •í™•í•˜ê²Œ 0/1/2+)
    # ---------------------------
    image_count = 0
    img_box = card.select_one(".s30AvhHfb0")

    if img_box:
        # â‘  2ê°œ ì´ìƒ â†’ ìˆ«ì span ì¡´ì¬
        count_span = img_box.select_one(".lOzR1kO8jf")
        if count_span:
            number = "".join(c for c in count_span.get_text(strip=True) if c.isdigit())
            if number:
                image_count = int(number)
        else:
            # â‘¡ ìˆ«ì span ì—†ìŒ + img ìˆìŒ â†’ 1ê°œ
            imgs = img_box.select("img")
            if len(imgs) >= 1:
                image_count = 1
    else:
        # â‘¢ img_box ìì²´ ì—†ìŒ â†’ 0ê°œ
        image_count = 0

    return {
        "nickname": nickname,
        "date": date,
        "rating": rating,
        "option": option,
        "auto_label": auto_label,
        "content": content,
        "image_count": image_count,
    }


# ================================
# ë¦¬ë·° ì „ì²´ ìˆ˜ì§‘
# ================================
def extract_reviews_to_csv(url, limit_pages=10):
    reviews = []
    seen = set()

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()

        print("â³ URL ì ‘ì† ì¤‘â€¦")
        page.goto(url, timeout=60000)
        time.sleep(3)

        print("ğŸ” ë¦¬ë·°íƒ­ í´ë¦­â€¦")
        try:
            page.click('[data-name="REVIEW"]')
            print("âœ” ë¦¬ë·°íƒ­ í´ë¦­ ì„±ê³µ")
            time.sleep(2)
        except:
            print("âŒ ë¦¬ë·°íƒ­ í´ë¦­ ì‹¤íŒ¨")
            browser.close()
            return

        for n in range(1, limit_pages + 1):
            print(f"\nğŸ“Œ {n} í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘â€¦")

            soup = BeautifulSoup(page.content(), "lxml")
            review_cards = soup.select(".IwcuBUIAKf")

            print(f"  - ê°ì§€ëœ ë¦¬ë·° ìˆ˜: {len(review_cards)}")

            for card in review_cards:
                info = parse_review_card(card)

                # ì¤‘ë³µ ì œê±°
                key = f"{info['nickname']}|{info['date']}|{info['content'][:20]}"
                if key not in seen:
                    seen.add(key)
                    reviews.append(info)

            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
            pagination = page.locator(".LiT9lKOVbw")
            next_btn = pagination.locator(f'a:has-text("{n+1}")').first

            if next_btn.count() > 0:
                print(f"â¡ {n+1} í˜ì´ì§€ ì´ë™")
                next_btn.click()
                time.sleep(2)
            else:
                print("â›” ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ â†’ ì¢…ë£Œ")
                break

        browser.close()

    df = pd.DataFrame(reviews)
    df.to_csv("reviews.csv", index=False, encoding="utf-8-sig")

    print("\n==========================================")
    print(f"âœ… ìµœì¢… ì €ì¥ëœ ë¦¬ë·° ìˆ˜: {len(reviews)}")
    print("ğŸ“ reviews.csv ìƒì„± ì™„ë£Œ")
    print("==========================================")


if __name__ == "__main__":
    test_url = "https://smartstore.naver.com/maca-mall/products/12491774443"
    extract_reviews_to_csv(test_url)
